{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163883ec-9fd7-429d-9d76-d22380a1656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image, ImageChops\n",
    "import requests\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import display\n",
    "\n",
    "SAMPLE_FRAME = \"sample.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973cd8a",
   "metadata": {},
   "source": [
    "### Step 1: Download a depth estimation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f9273-fe56-457d-a939-73f3126a4a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPE = None\n",
    "\n",
    "def get_pipe():\n",
    "    # This will load the pipeline on demand on the current PROCESS/THREAD.\n",
    "    # And load it only once.\n",
    "    global PIPE\n",
    "    if PIPE is None:\n",
    "        PIPE = pipeline(task=\"depth-estimation\", model=\"LiheYoung/depth-anything-large-hf\")\n",
    "    return PIPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f22a1e",
   "metadata": {},
   "source": [
    "### Step 2. Shift an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320691f9-7aba-4032-9b97-755ddedb6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(data, depth_img, shift_amount=10):\n",
    "    # Ensure depth image is grayscale (for single value)\n",
    "    data_with_alpha = np.dstack([data, np.full(data.shape[:2], 255, dtype=np.uint8)])\n",
    "    frame = Image.fromarray(data_with_alpha, \"RGBA\")\n",
    "    frame_depth = get_pipe()(frame)[\"depth\"]\n",
    "    depth_img = frame_depth.convert(\"L\")\n",
    "    depth_data = np.array(depth_img)\n",
    "    deltas = np.array((depth_data / 255.0) * float(shift_amount), dtype=int)\n",
    "\n",
    "    # This creates the transprent resulting image.\n",
    "    # For now, we're dealing with pixel data.\n",
    "    shifted_data = np.zeros_like(data_with_alpha)\n",
    "\n",
    "    width = frame.width\n",
    "    height = frame.height\n",
    "\n",
    "    for y, row in enumerate(deltas):\n",
    "        width = len(row)\n",
    "        x = 0\n",
    "        while x < width:\n",
    "            dx = row[x]\n",
    "            if x+dx >= width:\n",
    "                break\n",
    "            if x-dx < 0:\n",
    "                shifted_data[y][x-dx] = [0,0,0,0]\n",
    "            else:\n",
    "                shifted_data[y][x-dx] = data_with_alpha[y][x]\n",
    "            x += 1\n",
    "\n",
    "    # Convert the pixel data to an image.\n",
    "    shifted_image = Image.fromarray(shifted_data)\n",
    "\n",
    "    alphas_image = Image.fromarray(scipy.ndimage.binary_fill_holes(ImageChops.invert(shifted_image.getchannel(\"A\")))).convert(\"1\")\n",
    "    shifted_image.putalpha(ImageChops.invert(alphas_image))\n",
    "    return shifted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0143e81-44b6-4e7c-84ec-20848464affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_inpaint(img, amount):\n",
    "    shifted = shift_image(img, depth, shift_amount=amount).convert('RGB')\n",
    "    org_img = np.array(shifted)\n",
    "    damaged_img = np.array(shifted)\n",
    "    \n",
    "    # get the shape of the image\n",
    "    height, width = damaged_img.shape[0], damaged_img.shape[1]\n",
    "     \n",
    "    # Converting all pixels greater than zero to black while black becomes white\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if damaged_img[i, j].sum() > 0:\n",
    "                damaged_img[i, j] = 0\n",
    "            else:\n",
    "                damaged_img[i, j] = [255, 255, 255]\n",
    "     \n",
    "    # saving the mask \n",
    "    mask = cv2.cvtColor(damaged_img, cv2.COLOR_BGR2GRAY)\n",
    "    dst = cv2.inpaint(org_img, mask, 3, cv2.INPAINT_NS)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b44656-6900-4fc0-b78f-c28a0898ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_over_under_video_frame(frame):\n",
    "    idx, image = frame\n",
    "    print(idx)\n",
    "    left_img = shift_and_inpaint(image, 10)\n",
    "    right_img = shift_and_inpaint(image, 50)\n",
    "    \n",
    "    height, width, channels = left_img.shape\n",
    "    \n",
    "    stacked_img = cv2.vconcat([left_img, right_img])  # Combine images side by side\n",
    "    stacked_img = cv2.cvtColor(stacked_img, cv2.COLOR_BGR2RGB)\n",
    "    return (idx, stacked_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a3800",
   "metadata": {},
   "source": [
    "### Load a video and grab individual frames from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35597fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames(path):\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx == 10:\n",
    "            break\n",
    "            \n",
    "        # Read a new frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        yield (frame, frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb14762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'create_over_under_video_frame' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'create_over_under_video_frame' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "from torch.multiprocessing import Pool, Process, set_start_method\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = []\n",
    "    set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    VIDEO_PATH = \"sample.mov\"\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    frame_id = 0\n",
    "\n",
    "    multi_pool = Pool(processes=3)\n",
    "    frames = list(read_frames(VIDEO_PATH))\n",
    "    output = multi_pool.map(create_over_under_video_frame, list(frames[0]))\n",
    "    multi_pool.close()\n",
    "    multi_pool.join()\n",
    "\n",
    "    # fps = 30\n",
    "    # sorted_frames = sorted(frames, key=lambda x : x[0])\n",
    "    # clip = ImageSequenceClip(sorted_frames, fps=fps)\n",
    "    # video_path = 'sbs_3d_video.mp4'\n",
    "    # clip.write_videofile(video_path, codec='libx264', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
