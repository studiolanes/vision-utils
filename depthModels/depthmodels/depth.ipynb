{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163883ec-9fd7-429d-9d76-d22380a1656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image, ImageChops\n",
    "import requests\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_PATH =  os.path.expanduser(\"~/Desktop/profile.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698f9273-fe56-457d-a939-73f3126a4a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipe\n",
    "pipe = pipeline(task=\"depth-estimation\", model=\"LiheYoung/depth-anything-large-hf\")\n",
    "\n",
    "# load image\n",
    "image = Image.open(IMG_PATH)\n",
    "\n",
    "# inference\n",
    "depth = pipe(image)[\"depth\"]\n",
    "depth.save(os.path.expanduser(\"~/Downloads/depth.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "320691f9-7aba-4032-9b97-755ddedb6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(img, depth_img, shift_amount=10):\n",
    "    # Ensure base image has alpha\n",
    "    img = img.convert(\"RGBA\")\n",
    "    data = np.array(img)\n",
    "\n",
    "    # Ensure depth image is grayscale (for single value)\n",
    "    depth_img = depth_img.convert(\"L\")\n",
    "    depth_data = np.array(depth_img)\n",
    "    deltas = np.array((depth_data / 255.0) * float(shift_amount), dtype=int)\n",
    "\n",
    "    # This creates the transprent resulting image.\n",
    "    # For now, we're dealing with pixel data.\n",
    "    shifted_data = np.zeros_like(data)\n",
    "\n",
    "    width = img.width\n",
    "    height = img.height\n",
    "\n",
    "    for y, row in enumerate(deltas):\n",
    "        width = len(row)\n",
    "        x = 0\n",
    "        while x < width:\n",
    "            dx = row[x]\n",
    "            if x+dx >= width:\n",
    "                break\n",
    "            if x-dx < 0:\n",
    "                shifted_data[y][x-dx] = [0,0,0,0]\n",
    "            else:\n",
    "                shifted_data[y][x-dx] = data[y][x]\n",
    "            x += 1\n",
    "\n",
    "    # Convert the pixel data to an image.\n",
    "    shifted_image = Image.fromarray(shifted_data)\n",
    "\n",
    "    alphas_image = Image.fromarray(scipy.ndimage.binary_fill_holes(ImageChops.invert(shifted_image.getchannel(\"A\")))).convert(\"1\")\n",
    "    shifted_image.putalpha(ImageChops.invert(alphas_image))\n",
    "\n",
    "    return shifted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0143e81-44b6-4e7c-84ec-20848464affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_inpaint(path, amount):\n",
    "    shifted = shift_image(image, depth, shift_amount=amount).save(path)\n",
    "    org_img = cv2.imread(filename=path)\n",
    "    print(\"path\")\n",
    "    print(path)\n",
    "    damaged_img = cv2.imread(filename=path)\n",
    "    print(damaged_img.shape)\n",
    "    \n",
    "    # get the shape of the image\n",
    "    height, width = damaged_img.shape[0], damaged_img.shape[1]\n",
    "     \n",
    "    # Converting all pixels greater than zero to black while black becomes white\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if damaged_img[i, j].sum() > 0:\n",
    "                damaged_img[i, j] = 0\n",
    "            else:\n",
    "                damaged_img[i, j] = [255, 255, 255]\n",
    "     \n",
    "    # saving the mask \n",
    "    mask = cv2.cvtColor(damaged_img, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imshow(\"title\", mask)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    dst = cv2.inpaint(org_img, mask, 3, cv2.INPAINT_NS)\n",
    "    # Write the output.\n",
    "    cv2.imwrite(path, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17b44656-6900-4fc0-b78f-c28a0898ed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path\n",
      "/Users/herk/Downloads/cart_left.png\n",
      "(446, 669, 3)\n",
      "path\n",
      "/Users/herk/Downloads/cart_right.png\n",
      "(446, 669, 3)\n"
     ]
    }
   ],
   "source": [
    "shift_and_inpaint(\"/Users/herk/Downloads/cart_left.png\", 10)\n",
    "shift_and_inpaint(\"/Users/herk/Downloads/cart_right.png\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a50ff5-b49b-4f69-bd78-6f6ce451087b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
